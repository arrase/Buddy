import os
import sys
import argparse
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from langchain_google_genai import ChatGoogleGenerativeAI

# Adjust imports to new locations
from buddy_agent.core.graph import get_graph_app, configure_graph_dependencies, PlanExecuteState # Updated import
from buddy_agent.utils import read_file_content, read_directory_content

# Global console for CLI outputs
console = Console()

# Attempt to get API key from environment variable
# Actual key string removed as it should not be hardcoded.
# The user is expected to set GOOGLE_API_KEY environment variable.
GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")

def main():
    # Security Warning
    warning_title = "[bold red]!!! WARNING: Buddy AI Agent - Shell Command Execution !!![/bold red]"
    warning_message = (
        "This agent can execute shell commands generated by an AI model.\n"
        "Executing AI-generated commands can be [bold red]DANGEROUS[/bold red] and may lead to:\n"
        "- Unintended system modifications\n"
        "- Data loss or corruption\n"
        "- Security vulnerabilities\n\n"
        "ALWAYS review the generated plan and the specific commands before execution if possible, "
        "and only run this agent in a safe, isolated environment if you are unsure.\n"
        "[italic]You are responsible for any actions taken by this agent.[/italic]"
    )
    console.print(Panel(Markdown(warning_message), title=warning_title, border_style="red", expand=False))
    console.print("")  # For spacing

    if not GOOGLE_API_KEY:
        console.print(Markdown(":x: [bold red]Error:[/bold red] `GOOGLE_API_KEY` environment variable is not set. This is required to use the LLM."), style="red")
        sys.exit(1)

    # Initialize LLM
    llm = None
    try:
        # Recommended model, if user has access and API key supports it
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash-preview-04-17", google_api_key=GOOGLE_API_KEY, convert_system_message_to_human=True)
        console.print(Markdown(f":robot: LLM initialized with `gemini-2.5-flash-preview-04-17`."), style="dim")
    except Exception as e:
        console.print(Markdown(f":warning: Error initializing LLM with `gemini-2.5-flash-preview-04-17`: {e}. Attempting fallback to `gemini-pro`..."), style="yellow")
        try:
            llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=GOOGLE_API_KEY, convert_system_message_to_human=True)
            console.print(Markdown(f":robot: LLM initialized with fallback `gemini-pro`."), style="dim")
        except Exception as e_pro:
            console.print(Markdown(f":x: [bold red]LLM Initialization Failed:[/bold red] Could not initialize with `gemini-pro` either: {e_pro}. Please check your API key, model access, and internet connection."), style="red")
            sys.exit(1)

    # Configure the LLM and Console instances for the graph module
    configure_graph_dependencies(llm, console) # Updated function call

    parser = argparse.ArgumentParser(description="Buddy Agent: An AI assistant that can plan and execute tasks, including shell commands.")
    parser.add_argument(
        "-p", "--prompt",
        required=True,
        help="User prompt (direct string) or path to a text file containing the prompt."
    )
    parser.add_argument(
        "-c", "--context",
        required=False,
        default="",
        help="Path to a file or directory to load context from. If a directory, all files within will be read."
    )
    args = parser.parse_args()

    # Process Prompt input
    prompt_input = args.prompt
    user_prompt: str
    if os.path.isfile(prompt_input):
        console.print(Markdown(f":page_facing_up: Reading prompt from file: `{prompt_input}`"), style="dim")
        user_prompt = read_file_content(prompt_input) # read_file_content handles its own errors/exits
    else:
        # Assume it's a direct prompt string
        user_prompt = prompt_input
        console.print(Markdown(f":speech_balloon: Using direct prompt string."), style="dim")


    # Process Context input
    context_input = args.context
    context_data = ""
    if context_input:
        if os.path.isfile(context_input):
            console.print(Markdown(f":page_with_curl: Reading context from file: `{context_input}`"), style="dim")
            context_data = read_file_content(context_input) # Exits on error
        elif os.path.isdir(context_input):
            # read_directory_content now prints its own status "Reading content from directory..."
            context_data = read_directory_content(context_input) # Exits on error
        else:
            console.print(Markdown(f":warning: Context path `{context_input}` is not a valid file or directory. Proceeding without additional context."), style="yellow")
            context_data = "" # Ensure it's an empty string if path is invalid

    # Prepare Initial State for LangGraph
    initial_state: PlanExecuteState = {
        "prompt": user_prompt,
        "context": context_data,
        "plan": [],             # Will be populated by the planner
        "past_steps": [],       # Will be populated during execution
        "next_step_index": 0    # Start with the first step
    }

    console.rule("[bold blue]Buddy Agent Initializing")
    console.print(Markdown(f"**User Prompt:**\n```text\n{user_prompt}\n```"))
    if context_data:
        context_display_limit = 1000 # Characters
        if len(context_data) > context_display_limit:
             console.print(Markdown(f"**Context Provided (Preview):**\n```text\n{context_data[:context_display_limit]}...\n```" ))
        else:
             console.print(Markdown(f"**Context Provided:**\n```text\n{context_data}\n```" ))
    else:
        console.print(Markdown("*No context provided.*"))
    console.print("") # Spacing

    # Get the compiled LangGraph app
    app = get_graph_app()

    # Invoke the agent graph
    # The plan and step-by-step execution details are printed by the graph nodes themselves.
    final_state = {} # Ensure final_state is defined for the summary
    try:
        # The app.stream() method could be used for more granular output if needed,
        # but for now, assuming nodes handle their own printing.
        for event in app.stream(initial_state):
            # You can inspect events here if needed, e.g., print node names as they run
            # console.print(f"Event: {event}")
            if "__end__" in event: # Check if it's the end event
                final_state = event["__end__"]
                break
            else:
                # The last key in the event dictionary is usually the node that just ran
                last_event_key = list(event.keys())[-1]
                final_state.update(event[last_event_key])


    except Exception as e:
        console.print(Markdown(f"\n:x: [bold red]Agent Execution Failed Critically:[/bold red]\nAn unexpected error occurred during the main agent execution loop: {e}"))
        # final_state might be partially updated or empty depending on when the error occurred.
        # The summary below will show what's available.

    console.rule("[bold green]Agent Execution Complete")

    console.print(Markdown("### Final Plan Executed:"))
    if 'plan' in final_state and final_state.get('plan'):
        md_final_plan = "\n".join([f"{i+1}. {step}" for i, step in enumerate(final_state['plan'])])
        console.print(Markdown(md_final_plan if md_final_plan.strip() else "*Plan was empty or contained no actionable steps.*"))
    else:
        console.print(Markdown("*No plan was part of the final state or it was empty.*"))
    console.print("")

    console.print(Markdown("### Execution History:"))
    if 'past_steps' in final_state and final_state.get('past_steps'):
        if not final_state['past_steps']: # Check if list is empty
            console.print(Markdown("*No steps were executed or recorded.*"))
        for step_taken, result_of_step in final_state['past_steps']:
            console.print(Markdown(f"- **Step:** {step_taken}\n  **Result:**\n{result_of_step if result_of_step.strip() else '*No output from this step.*'}"))
            console.print("") # Spacer between history items
    else:
        console.print(Markdown("*No steps were recorded in the execution history.*"))
    console.rule(style="bold green")

if __name__ == "__main__":
    main()
